---
title: "Archived but not lost"
---

CRAN packages are often archived and equally often after being taken off CRAN they can be brought up to CRAN.

This dashboard updates with the latest 40 days of CRAN archived or unarchived packages from the [document](https://cran.r-project.org/src/contrib/PACKAGES.in) the CRAN team uses to document this process.

To avoid being archived follow [CRAN policies](https://cran.r-project.org/web/packages/policies.html) fix the package in time.
If you don't think you can reach the deadline you got, you might be able to convince the CRAN maintainers to extend the deadline.

If your package has already been archived, you can get back to CRAN by fixing the issues pointed on the initial email, as well as any other new issue that might show up.
Check the package before sending it and explain to the volunteers how you fixed it.
If you have problems you don't know how to solve, you can search for a solution in the r-package-devel mailing list and ask there for help with the package development 

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  warning = FALSE,
  message = FALSE,
  echo = FALSE
)
```


```{r}
library("dplyr")
logic2string <- function(x){
  y <- NA
  y[x] <- "yes"
  y[!x] <- "no"
  y
}
url <- "https://cran.r-project.org/src/contrib/PACKAGES.in"
con <- url(url)
file <- read.dcf(con) |> 
  as.data.frame()

# Extract multiline comments
comments_l <- lapply(file$`X-CRAN-Comment`, function(x) {
  unlist(strsplit(x, "[\n]+"), FALSE, FALSE)
})
comments_c <- unlist(comments_l)
df <- data.frame(package = rep(file$Package, lengths(comments_l)),
           comment = comments_c)
regex_date <- "([0-9]{4}-[0-9]{2}-[0-9]{2})"
regex_action <- "([Uu]narchived?|[Aa]rchived?|[Rr]enamed?|[Oo]rphaned?|[Rr]eplaced?|[Rr]emoved?)"
comments_df <- cbind(df, 
           strcapture(pattern = regex_date, x = df$comment, 
                      proto = data.frame(date = Sys.Date()[0])),
           strcapture(pattern = regex_action, x = df$comment,
                      proto = data.frame(action = character()))
           ) |> 
  filter(!is.na(comment)) |> 
  mutate(action = tolower(action))
# Check that count(comments_df, !is.na(date), !is.na(action), sort = TRUE) makes sense
# Handle rolled and no keyword used
comments_df$action[!is.na(comments_df$date) & is.na(comments_df$action)] <- "archived"

# filter(comments_df, !is.na(action) & is.na(date)) |> View("a")
# filter(comments_df, is.na(action) & is.na(date)) |> View("b")
# Handle CRAN-history
history_l <- lapply(file$`X-CRAN-History`, function(x) {
  unlist(strsplit(x, "[\n]+"), FALSE, FALSE)
})
history_c <- unlist(history_l)

history_df <- data.frame(package = rep(file$Package, lengths(history_l)),
                    comment = history_c) |> 
  filter(!is.na(comment))

history_df <- cbind(history_df,
                    strcapture(pattern = regex_date, x = history_df$comment, 
                               proto = data.frame(date = Sys.Date()[0])),
                    strcapture(pattern = regex_action, x = history_df$comment,
                               proto = data.frame(action = character()))
           ) |> 
  mutate(action = tolower(action))
history_df$action[grep("Back on CRAN", history_df$comment, ignore.case = TRUE)] <- "unarchived"
library("reactable")
history <- rbind(comments_df, history_df) |> 
  mutate(action = gsub(pattern = "e$", replacement = "ed", action)) |> 
  arrange(package) |> 
  filter(action %in% c("archived", "unarchived"),
         !is.na(date),
         !is.na(action)) 
  
# Show only the last 40 days
history |> 
  filter(date > (Sys.Date() - 40)) |> 
  reactable(
    columns = list(
      action = colDef(style = function(value) {
        colours <- list("unarchived" = "green")
        if (value %in% names(colours)) {
          list(background = colours[[value]])
        } else {
          list()
        }
      })),
    defaultSorted = list("date" = "desc"),
    filterable = TRUE,
    defaultPageSize = 50)
```


# Background

Many packages get back to CRAN after being archived:

```{r}
archive <- tools:::CRAN_archive_db()
pkges <- unique(history$package[history$action %in% c("archived", "unarchived")])

# packages in archive
pkgs <- intersect(pkges, names(archive))
relevant_archive <- archive[pkgs]
archive_df <- do.call(rbind, relevant_archive)

archives <- vapply(relevant_archive, nrow, numeric(1))
pkg <- rep(names(relevant_archive), times = archives)
archive_df$package <- pkg

current <- tools:::CRAN_current_db()
current$package <- gsub("(.*)_.*\\.tar\\.gz$", "\\1", rownames(current))
relevant_current <- current[current$package %in% pkgs, ]

packages <- rbind(archive_df, relevant_current) |> 
  mutate(date = as.Date(mtime), action = "new") |> 
  arrange(package, date) |> 
  select(date, package, action)

rownames(packages) <- NULL
```


```{r}
out <- merge(packages, history, all = TRUE, sort = FALSE) |> 
  arrange(package, date) 

# There is no package that the unarchived date isn't recorded as new
out |> 
  summarise(.by = package, 
            n_unarchive = sum(action == "unarchived"),
            n_archive = sum(action == "archived"),
            k = any(date[action == "unarchive"] != date[action == "new"])) |> 
  filter(k)

# Packages with problems with annotation about being archived
over_unarchived <- out |> 
  summarise(.by = package,
            missing = sum(action == "unarchived") > sum(action == "archived")) |> 
  filter(missing) |> 
  pull(package)

more <- out |> 
  filter(action != "unarchived") |> 
  filter(!package %in% over_unarchived) |> 
  group_by(package) |> 
  filter(cumsum(action == "archived") >= 1) |>
  filter(!all(action == "archived")) |> 
  # filter(ar > 0 & n > ar) |> 
  mutate(lead = lead(action, default = NA),
         lag = lag(action, default = NA)) |> 
  filter((action == "archived" & lead == "new") | 
           (action == "new" & lag == "archived")) |>
  mutate(group = rep(letters, each = 2, length.out = n())) |> 
  ungroup()

library("tidyr")
pw <- more |> 
  select(package, group, action, date) |> 
  pivot_wider(names_from =action, values_from = date) |> 
  mutate(timediff = difftime(new, archived, units = "days"))
```

```{r}
library("ggplot2")
fiu <- function(x){is(x, "difftime")}
pw |> summarise(.by = group, 
                packages = n(), 
                min = min(timediff), 
                q1 = quantile(timediff, 0.25), 
                mean = mean(timediff), 
                m = median(timediff), 
                q3 = quantile(timediff, 0.75), 
                max = max(timediff)) |> 
  mutate(across(where(fiu), round)) |> 
  as.data.frame()


pw |> 
  filter(group == "a") |> 
  ggplot() +
  stat_ecdf(aes(timediff)) +
  coord_cartesian(xlim =  c(0, 365))

pw |> 
  arrange(archived) |> 
  mutate(n = cumsum(seq_len(n()))) |> 
  ggplot() +
  geom_line(aes(archived, n)) +
  theme_minimal() +
  scale_y_log10(guide = "axis_logticks")

pw |> 
  ggplot() +
  geom_count(aes(archived, timediff)) +
  geom_abline(slope = -1, intercept = Sys.Date(), linetype = 2, col = "gray") +
  geom_rug(aes(archived, timediff), sides = "b", outside = TRUE, length = unit(0.015, "npc"), 
           col = "gray") +
  theme_minimal() +
  coord_cartesian(clip = "off") +
  scale_y_continuous(expand = expansion(c(0, NA), c(0, NA))) +
  labs(x = "Date when the package was archived",
       y = "Time until it went back to CRAN",
       title = "Time till packages are back to CRAN")
pw |> 
  ggplot() +
  geom_histogram(aes(timediff), binwidth = 7) +
  theme_minimal() +
  scale_y_continuous(expand = expansion(c(0, NA), c(0, NA))) +
  labs(y = "Packages that got back",
       x = "Time until it went back to CRAN",
       title = "Time till packages are back to CRAN")
```

